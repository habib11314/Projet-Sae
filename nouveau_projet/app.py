#!/usr/bin/env python3
"""
StatEnergie - Application professionnelle d'analyse √©nerg√©tique
Solution compl√®te pour entreprises du secteur √©nerg√©tique
"""

from flask import Flask, render_template, request, jsonify, send_file, redirect, url_for, flash
import pandas as pd
import numpy as np
import plotly.graph_objs as go
import plotly.utils
import json
import os
import uuid
from datetime import datetime, timedelta
from werkzeug.utils import secure_filename
import tempfile
import io
import traceback
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter, A4
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image
from reportlab.lib.units import inch
from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_RIGHT
from pdf_bill_analyzer import PDFBillAnalyzer

app = Flask(__name__)
app.config['SECRET_KEY'] = 'statenergie-secret-key-2025'
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# Cr√©er le dossier uploads s'il n'existe pas
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# Extensions autoris√©es
ALLOWED_EXTENSIONS = {'csv', 'xlsx', 'json', 'pdf'}

def allowed_file(filename):
    """V√©rifier si le fichier est autoris√©"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def detect_data_format(df):
    """D√©tecter automatiquement le format des donn√©es √©nerg√©tiques professionnelles"""
    columns = df.columns.str.lower()
    
    # 1. FORMAT GRD-F (Courbes de charge - Enedis/EDF/ENGIE)
    has_pdl_prm = any('pdl' in col or 'prm' in col for col in columns)
    has_index = any('index' in col for col in columns)
    has_datetime = any('date' in col and 'heure' in col for col in columns) or any('datetime' in col for col in columns)
    has_hp_hc = any('hp' in col for col in columns) and any('hc' in col for col in columns)
    has_conso_interval = any('conso' in col for col in columns) and (has_datetime or has_index)
    
    if (has_pdl_prm and has_index) or (has_conso_interval and has_hp_hc):
        return 'grdf_courbe_charge'
    
    # 2. FORMAT FACTURES NORMALIS√âES (Comptabilit√© entreprise)
    has_client = any('client' in col or 'num√©ro' in col for col in columns)
    has_periode = any('p√©riode' in col or 'factur√©' in col for col in columns)
    has_montant = any('montant' in col or 'prix' in col or 'tarif' in col for col in columns)
    has_taxes = any('taxe' in col or 'tva' in col or 'cspe' in col or 'cta' in col for col in columns)
    has_fournisseur = any('fournisseur' in col or 'engie' in col or 'edf' in col for col in columns)
    
    if (has_client and has_montant) or (has_periode and has_fournisseur) or has_taxes:
        return 'factures_normalisees'
    
    # 3. FORMAT ADEME / ISO 50001 (Management √©nerg√©tique)
    has_iso_indicators = any('indicateur' in col or 'performance' in col for col in columns)
    has_energy_type = any('type' in col and 'energie' in col for col in columns)
    has_kpi = any('kpi' in col or 'objectif' in col or 'cible' in col for col in columns)
    has_ademe = any('ademe' in col or 'iso' in col or '50001' in col for col in columns)
    has_management = any('management' in col or 'pilotage' in col for col in columns)
    
    if has_iso_indicators or has_kpi or has_ademe or has_management:
        return 'ademe_iso50001'
    
    # Fallback: d√©tecter un format g√©n√©rique si aucun format sp√©cialis√© n'est reconnu
    has_basic_conso = any('consommation' in col or 'consumption' in col for col in columns)
    has_basic_date = any('date' in col for col in columns)
    
    if has_basic_conso and has_basic_date:
        return 'format_generique'
    
    return 'format_non_reconnu'

def standardize_columns(df, data_format):
    """Standardiser les noms de colonnes selon le format d√©tect√©"""
    df_std = df.copy()
    
    print(f"üîç Colonnes originales: {list(df_std.columns)}")
    print(f"üéØ Format d√©tect√©: {data_format}")
    
    if data_format == 'grdf_courbe_charge':
        # Format GRD-F / Courbes de charge
        column_mapping = {}
        
        for col in df_std.columns:
            col_lower = col.lower()
            
            # Date/heure
            if 'date' in col_lower and ('heure' in col_lower or 'time' in col_lower):
                column_mapping[col] = 'datetime'
                print(f"üìÖ Colonne datetime d√©tect√©e: '{col}' -> 'datetime'")
            elif 'date' in col_lower:
                column_mapping[col] = 'date'
                print(f"üìÖ Colonne date d√©tect√©e: '{col}' -> 'date'")
            
            # Index cumul√©
            elif 'index' in col_lower:
                column_mapping[col] = 'index_cumul'
                print(f"üìä Index cumul√©: '{col}' -> 'index_cumul'")
            
            # Consommation par intervalle
            elif 'conso' in col_lower and ('kwh' in col_lower or 'mwh' in col_lower):
                column_mapping[col] = 'consumption'
                print(f"‚ö° Consommation: '{col}' -> 'consumption'")
            
            # HP/HC
            elif 'hp' in col_lower and 'conso' in col_lower:
                column_mapping[col] = 'hp_consumption'
                print(f"üåû HP: '{col}' -> 'hp_consumption'")
            elif 'hc' in col_lower and 'conso' in col_lower:
                column_mapping[col] = 'hc_consumption'
                print(f"üåô HC: '{col}' -> 'hc_consumption'")
            
            # Point de livraison
            elif 'pdl' in col_lower or 'prm' in col_lower:
                column_mapping[col] = 'point_livraison'
                print(f"üè¢ Point livraison: '{col}' -> 'point_livraison'")
        
        df_std = df_std.rename(columns=column_mapping)
        
        # Calculer la consommation si on a HP+HC
        if 'hp_consumption' in df_std.columns and 'hc_consumption' in df_std.columns and 'consumption' not in df_std.columns:
            df_std['consumption'] = df_std['hp_consumption'] + df_std['hc_consumption']
            print("ÔøΩ Consommation totale calcul√©e: HP + HC")
    
    elif data_format == 'factures_normalisees':
        # Format factures normalis√©es
        column_mapping = {}
        consumption_mapped = False  # Flag pour √©viter les doublons sur 'consumption'
        
        for col in df_std.columns:
            col_lower = col.lower()
            
            # Num√©ro client/Site
            if ('client' in col_lower or 'num√©ro' in col_lower or 'site' in col_lower) and 'numero_client' not in column_mapping.values():
                column_mapping[col] = 'numero_client'
                print(f"üë§ Num√©ro client/Site: '{col}' -> 'numero_client'")
            
            # P√©riode/Mois
            elif ('p√©riode' in col_lower or 'mois' in col_lower or 'date' in col_lower) and 'periode' not in column_mapping.values():
                column_mapping[col] = 'periode'
                print(f"üìÖ P√©riode: '{col}' -> 'periode'")
            
            # Consommations (ordre de priorit√© pour √©viter les conflits)
            elif not consumption_mapped and ('consommation' in col_lower and ('totale' in col_lower or 'total' in col_lower)):
                column_mapping[col] = 'consumption'
                consumption_mapped = True
                print(f"‚ö° Consommation totale: '{col}' -> 'consumption'")
            elif not consumption_mapped and ('conso' in col_lower and 'hp' in col_lower):
                column_mapping[col] = 'hp_consumption'
                print(f"ÔøΩ Conso HP: '{col}' -> 'hp_consumption'")
            elif not consumption_mapped and ('conso' in col_lower and 'hc' in col_lower):
                column_mapping[col] = 'hc_consumption'
                print(f"üåô Conso HC: '{col}' -> 'hc_consumption'")
            elif not consumption_mapped and ('conso' in col_lower or 'consommation' in col_lower) and 'kwh' in col_lower:
                column_mapping[col] = 'consumption'
                consumption_mapped = True
                print(f"‚ö° Consommation: '{col}' -> 'consumption'")
            
            # Montants (ordre de priorit√©)
            elif ('montant' in col_lower and ('ht' in col_lower or 'hors' in col_lower)) and 'montant_ht' not in column_mapping.values():
                column_mapping[col] = 'montant_ht'
                print(f"üí∞ Montant HT: '{col}' -> 'montant_ht'")
            elif ('montant' in col_lower and ('ttc' in col_lower or 'toutes' in col_lower)) and 'montant_ttc' not in column_mapping.values():
                column_mapping[col] = 'montant_ttc'
                print(f"üí∞ Montant TTC: '{col}' -> 'montant_ttc'")
            elif ('montant' in col_lower and 'factur' in col_lower) and 'montant_ttc' not in column_mapping.values():
                column_mapping[col] = 'montant_ttc'  # Assumer TTC pour "montant factur√©"
                print(f"üí∞ Montant factur√©: '{col}' -> 'montant_ttc'")
            elif ('montant' in col_lower or ('‚Ç¨' in col and 'montant' in col_lower)) and 'montant' not in column_mapping.values():
                column_mapping[col] = 'montant'
                print(f"üí∞ Montant: '{col}' -> 'montant'")
            
            # Fournisseur
            elif 'fournisseur' in col_lower and 'fournisseur' not in column_mapping.values():
                column_mapping[col] = 'fournisseur'
                print(f"üè¢ Fournisseur: '{col}' -> 'fournisseur'")
            
            # Taxes
            elif any(tax in col_lower for tax in ['tva', 'cspe', 'cta', 'taxe']) and 'taxes' not in column_mapping.values():
                column_mapping[col] = 'taxes'
                print(f"üèõÔ∏è Taxes: '{col}' -> 'taxes'")
        
        # Appliquer le mapping
        df_std = df_std.rename(columns=column_mapping)
        
        # Calculer la consommation totale si HP+HC mais pas de consommation totale
        if 'hp_consumption' in df_std.columns and 'hc_consumption' in df_std.columns and 'consumption' not in df_std.columns:
            df_std['consumption'] = df_std['hp_consumption'] + df_std['hc_consumption']
            print("‚ö° Consommation totale calcul√©e: HP + HC")
    
    elif data_format == 'ademe_iso50001':
        # Format ADEME / ISO 50001
        column_mapping = {}
        
        for col in df_std.columns:
            col_lower = col.lower()
            
            # Indicateurs de performance
            if 'indicateur' in col_lower or 'kpi' in col_lower:
                column_mapping[col] = 'kpi_energetique'
                print(f"üìä KPI √©nerg√©tique: '{col}' -> 'kpi_energetique'")
            
            # Objectifs/Cibles
            elif 'objectif' in col_lower or 'cible' in col_lower:
                column_mapping[col] = 'objectif'
                print(f"üéØ Objectif: '{col}' -> 'objectif'")
            
            # Type d'√©nergie
            elif 'type' in col_lower and 'energie' in col_lower:
                column_mapping[col] = 'type_energie'
                print(f"‚ö° Type √©nergie: '{col}' -> 'type_energie'")
            
            # Performance
            elif 'performance' in col_lower:
                column_mapping[col] = 'performance'
                print(f"üìà Performance: '{col}' -> 'performance'")
            
            # Consommation
            elif 'consommation' in col_lower or 'consumption' in col_lower:
                column_mapping[col] = 'consumption'
                print(f"‚ö° Consommation: '{col}' -> 'consumption'")
        
        df_std = df_std.rename(columns=column_mapping)
    
    elif data_format == 'format_generique':
        # Format g√©n√©rique de base
        for col in df_std.columns:
            col_lower = col.lower()
            if 'consommation' in col_lower or 'consumption' in col_lower:
                df_std['consumption'] = df_std[col]
            elif 'date' in col_lower:
                df_std['date'] = df_std[col]
    
    print(f"üîÑ Colonnes apr√®s standardisation: {list(df_std.columns)}")
    return df_std

def analyze_consumption_data(df):
    """Analyse ultra-avanc√©e des donn√©es de consommation selon le format professionnel d√©tect√©"""
    
    # D√©tecter le format et standardiser les colonnes
    data_format = detect_data_format(df)
    df_standardized = standardize_columns(df, data_format)
    
    # V√©rification critique : s'assurer que df_standardized est bien un DataFrame
    if not isinstance(df_standardized, pd.DataFrame):
        print(f"‚ùå ERREUR CRITIQUE: standardize_columns a retourn√© {type(df_standardized)} au lieu d'un DataFrame")
        print(f"üìÑ Contenu retourn√©: {repr(df_standardized)}")
        raise TypeError(f"standardize_columns a retourn√© {type(df_standardized)} au lieu d'un DataFrame")
    
    df = df_standardized
    print(f"üîç Colonnes apr√®s standardisation: {list(df.columns)}")
    
    # Utiliser l'analyseur sp√©cialis√© selon le format
    if data_format == 'grdf_courbe_charge':
        try:
            from analyzers_specialized import analyze_grdf_courbe_charge
            results = analyze_grdf_courbe_charge(df)
            results['columns'] = list(df.columns)
            return results
        except Exception as e:
            print(f"‚ùå Erreur analyse GRD-F: {e}")
            import traceback; traceback.print_exc()
    
    elif data_format == 'factures_normalisees':
        try:
            from analyzers_specialized import analyze_factures_normalisees
            results = analyze_factures_normalisees(df)
            results['columns'] = list(df.columns)
            return results
        except Exception as e:
            print(f"‚ùå Erreur analyse factures: {e}")
            import traceback; traceback.print_exc()
    
    elif data_format == 'ademe_iso50001':
        try:
            from analyzers_specialized import analyze_ademe_iso50001
            results = analyze_ademe_iso50001(df)
            results['columns'] = list(df.columns)
            return results
        except Exception as e:
            print(f"‚ùå Erreur analyse ADEME: {e}")
            import traceback; traceback.print_exc()
    
    elif data_format == 'format_non_reconnu':
        return {
            'error': f'Format de fichier non reconnu. Formats support√©s: GRD-F (courbes de charge), Factures normalis√©es, ADEME/ISO 50001',
            'data_format': data_format,
            'file_info': {'columns_detected': list(df.columns)},
            'supported_formats': [
                'GRD-F / Courbes de charge (Enedis, EDF, ENGIE)',
                'Factures normalis√©es (comptabilit√© entreprise)', 
                'ADEME / ISO 50001 (management √©nerg√©tique)'
            ]
        }
    
    # Fallback pour format g√©n√©rique
    print("‚ö†Ô∏è  Utilisation de l'analyse g√©n√©rique (format non sp√©cialis√©)")
    
    # Convertir les dates
    if 'date' in df.columns:
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        print(f"üìÖ Dates converties - plage: {df['date'].min()} √† {df['date'].max()}")
    else:
        print("‚ö†Ô∏è  Aucune colonne 'date' trouv√©e - ajout de dates par d√©faut")
        df['date'] = pd.date_range(start='2024-01-01', periods=len(df), freq='D')
    
    # Nettoyer les donn√©es num√©riques
    numeric_columns = ['consumption', 'total_consumption', 'hp_consumption', 'hc_consumption', 'estimated_bill']
    for col in numeric_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            print(f"üî¢ Colonne {col} convertie en num√©rique")
    
    # D√©terminer la colonne de consommation
    consumption_col = None
    if 'consumption' in df.columns:
        consumption_col = 'consumption'
    elif 'total_consumption' in df.columns:
        consumption_col = 'total_consumption'
    elif 'hp_consumption' in df.columns:
        consumption_col = 'hp_consumption'
    else:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            consumption_col = numeric_cols[0]
            df['consumption'] = df[consumption_col]
            print(f"üî¢ Utilisation de la colonne num√©rique: {consumption_col}")
    
    if consumption_col is None:
        return {
            'error': 'Aucune donn√©e de consommation valide trouv√©e',
            'data_format': data_format,
            'file_info': {'columns_detected': list(df.columns)},
            'basic_stats': {},
            'advanced_stats': {},
            'peaks': [],
            'trends': {},
            'recommendations': [],
            'cost_analysis': {},
            'environmental_impact': {},
            'benchmarking': {},
            'solutions': []
        }
    
    df = df.dropna(subset=[consumption_col])
    print(f"üìä Lignes valides apr√®s nettoyage: {len(df)} (colonne utilis√©e: {consumption_col})")
    
    if len(df) == 0:
        return {
            'error': 'Aucune donn√©e de consommation valide trouv√©e',
            'data_format': data_format,
            'file_info': {},
            'basic_stats': {},
            'advanced_stats': {},
            'peaks': [],
            'trends': {},
            'recommendations': [],
            'cost_analysis': {},
            'environmental_impact': {},
            'benchmarking': {},
            'solutions': []
        }
    
    # === INFORMATIONS DU FICHIER ===
    file_info = {
        'total_records': len(df),
        'data_format': data_format,
        'columns_detected': list(df.columns),
        'date_range': {
            'start': 'Non sp√©cifi√©',
            'end': 'Non sp√©cifi√©', 
            'duration_days': 0
        },
        'data_quality': {
            'missing_values': df[consumption_col].isna().sum(),
            'zero_values': (df[consumption_col] == 0).sum(),
            'negative_values': (df[consumption_col] < 0).sum(),
            'quality_score': calculate_data_quality_score(df)
        }
    }
    
    # Ajouter les informations de date si disponibles
    if 'date' in df.columns and not df['date'].isna().all():
        try:
            file_info['date_range'] = {
                'start': str(df['date'].min()),
                'end': str(df['date'].max()),
                'duration_days': (pd.to_datetime(df['date'].max()) - pd.to_datetime(df['date'].min())).days + 1
            }
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur lors du calcul de la plage de dates: {e}")
            # Garder les valeurs par d√©faut
    
    # === STATISTIQUES DE BASE ===
    consumption = df[consumption_col]
    basic_stats = {
        'total_consumption': float(consumption.sum()),
        'avg_consumption': float(consumption.mean()),
        'max_consumption': float(consumption.max()),
        'min_consumption': float(consumption.min()),
        'std_consumption': float(consumption.std()),
        'median_consumption': float(consumption.median())
    }
    
    # === ANALYSES SP√âCIFIQUES SELON LE FORMAT ===
    hp_hc_analysis = None
    zone_analysis = None
    billing_analysis = None
    
    if data_format == 'enterprise_advanced':
        # Analyse HP/HC
        if 'hp_consumption' in df.columns and 'hc_consumption' in df.columns:
            hp_hc_analysis = analyze_hp_hc_consumption(df)
        
        # Analyse par zones
        if 'zone' in df.columns:
            zone_analysis = analyze_zone_consumption(df)
        
        # Analyse de facturation
        if 'estimated_bill' in df.columns:
            billing_analysis = analyze_billing_patterns(df)
    
    # === STATISTIQUES AVANC√âES ===
    advanced_stats = {
        'quartiles': {
            'q1': float(consumption.quantile(0.25)),
            'q3': float(consumption.quantile(0.75)),
            'iqr': float(consumption.quantile(0.75) - consumption.quantile(0.25))
        },
        'distribution': {
            'skewness': float(consumption.skew()),
            'kurtosis': float(consumption.kurtosis()),
            'coefficient_variation': float(consumption.std() / consumption.mean()) if consumption.mean() > 0 else 0
        },
        'patterns': analyze_consumption_patterns(df),
        'seasonal_analysis': analyze_seasonal_patterns(df),
        'efficiency_metrics': calculate_efficiency_metrics(consumption)
    }
    
    # === D√âTECTION DES PICS ===
    threshold = basic_stats['avg_consumption'] + 1.5 * basic_stats['std_consumption']
    peaks_df = df[df[consumption_col] > threshold]
    
    peaks = []
    for _, peak in peaks_df.iterrows():
        peaks.append({
            'date': str(peak['date']) if 'date' in peak else 'N/A',
            'value': float(peak[consumption_col]),
            'percentage_above_avg': float(((peak[consumption_col] - basic_stats['avg_consumption']) / basic_stats['avg_consumption']) * 100),
            'severity': classify_peak_severity(peak[consumption_col], basic_stats['avg_consumption'], basic_stats['std_consumption']),
            'impact_cost': estimate_peak_cost_impact(peak[consumption_col], basic_stats['avg_consumption'])
        })
    
    # === ANALYSE DES TENDANCES ===
    trends = analyze_detailed_trends(df)
    
    # === ANALYSE DES CO√õTS ===
    cost_analysis = calculate_cost_analysis(basic_stats, peaks, file_info)
    
    # === IMPACT ENVIRONNEMENTAL ===
    environmental_impact = calculate_environmental_impact(basic_stats, file_info)
    
    # === BENCHMARKING ===
    benchmarking = perform_benchmarking(basic_stats, file_info)
    
    # === RECOMMANDATIONS AVANC√âES ===
    recommendations = generate_advanced_recommendations({
        'basic_stats': basic_stats,
        'advanced_stats': advanced_stats,
        'peaks': peaks,
        'trends': trends,
        'cost_analysis': cost_analysis,
        'environmental_impact': environmental_impact,
        'benchmarking': benchmarking,
        'file_info': file_info
    })
    
    # === SOLUTIONS CONCR√àTES ===
    solutions = generate_concrete_solutions(recommendations, cost_analysis)
    
    return {
        'file_info': file_info,
        'basic_stats': basic_stats,
        'advanced_stats': advanced_stats,
        'peaks': peaks,
        'trends': trends,
        'cost_analysis': cost_analysis,
        'environmental_impact': environmental_impact,
        'benchmarking': benchmarking,
        'recommendations': recommendations,
        'solutions': solutions,
        # Nouvelles analyses pour format entreprise
        'hp_hc_analysis': hp_hc_analysis,
        'zone_analysis': zone_analysis,
        'billing_analysis': billing_analysis,
        'data_format': data_format,
        # Compatibilit√© avec l'ancien format
        'total_consumption': basic_stats['total_consumption'],
        'avg_consumption': basic_stats['avg_consumption'],
        'max_consumption': basic_stats['max_consumption'],
        'min_consumption': basic_stats['min_consumption'],
        'std_consumption': basic_stats['std_consumption'],
        'statistics': {
            'median': basic_stats['median_consumption'],
            'quartile_25': advanced_stats['quartiles']['q1'],
            'quartile_75': advanced_stats['quartiles']['q3'],
            'coefficient_variation': advanced_stats['distribution']['coefficient_variation'],
            'efficiency_score': advanced_stats['efficiency_metrics']['overall_score']
        }
    }

def create_advanced_chart(df, analysis):
    """Cr√©e un graphique avanc√© avec Plotly - harmonis√© pour tous les formats"""
    try:
        print(f"üîç Debug graphique - colonnes disponibles: {list(df.columns)}")
        
        if 'date' not in df.columns:
            print("‚ùå Colonne 'date' manquante dans le DataFrame")
            return None
            
        fig = go.Figure()
        
        # Pr√©parer les donn√©es
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date')
        
        # D√©tecter le format de donn√©es
        data_format = analysis.get('data_format', 'standard')
        
        # D√©terminer la colonne de consommation principale
        consumption_col = None
        if 'consumption' in df.columns:
            consumption_col = 'consumption'
        elif 'total_consumption' in df.columns:
            consumption_col = 'total_consumption'
        
        if not consumption_col:
            print("‚ùå Aucune colonne de consommation trouv√©e")
            return None
            
        # Graphique unifi√© pour tous les formats
        print(f"üìä G√©n√©ration graphique unifi√© - Format: {data_format}")
        df[consumption_col] = pd.to_numeric(df[consumption_col], errors='coerce')
        
        # Nom unifi√© pour tous les formats
        graph_name = 'Consommation (kWh)'
        tooltip_label = 'Consommation'
        
        # Ligne principale unique pour tous les formats
        fig.add_trace(go.Scatter(
            x=df['date'],
            y=df[consumption_col],
            mode='lines+markers',
            name=graph_name,
            line=dict(color='#2E86AB', width=4),
            marker=dict(size=8),
            hovertemplate=f'<b>Date:</b> %{{x}}<br><b>{tooltip_label}:</b> %{{y:.1f}} kWh<extra></extra>'
        ))
        
        # Ligne de moyenne (adapt√©e aux diff√©rentes structures)
        if 'basic_stats' in analysis and 'avg_consumption' in analysis['basic_stats']:
            avg_consumption = analysis['basic_stats']['avg_consumption']
            std_consumption = analysis['basic_stats'].get('std_consumption', 0)
        else:
            avg_consumption = analysis.get('avg_consumption', df[consumption_col].mean())
            std_consumption = analysis.get('std_consumption', df[consumption_col].std())
        
        fig.add_hline(
            y=avg_consumption,
            line_dash="dash",
            line_color="orange",
            annotation_text=f"Moyenne: {avg_consumption:.1f} kWh",
            annotation_position="top right"
        )
        
        # Seuil d'alerte
        alert_threshold = avg_consumption + 1.5 * std_consumption
        fig.add_hline(
            y=alert_threshold,
            line_dash="dot",
            line_color="red",
            annotation_text=f"Seuil d'alerte: {alert_threshold:.1f} kWh",
            annotation_position="top right"
        )
        
        # Marquer les pics (toujours sur la consommation principale)
        if analysis['peaks']:
            peak_dates = [pd.to_datetime(peak['date']) for peak in analysis['peaks']]
            peak_values = [peak['value'] for peak in analysis['peaks']]
            
            fig.add_trace(go.Scatter(
                x=peak_dates,
                y=peak_values,
                mode='markers',
                name='Pics de consommation',
                marker=dict(color='red', size=12, symbol='triangle-up'),
                hovertemplate='<b>Pic d√©tect√©</b><br><b>Date:</b> %{x}<br><b>Consommation:</b> %{y:.1f} kWh<extra></extra>'
            ))
        
        # Moyennes mobiles (toujours sur la consommation principale)
        if len(df) >= 7:
            df['ma_7'] = df[consumption_col].rolling(window=7, center=True).mean()
            fig.add_trace(go.Scatter(
                x=df['date'],
                y=df['ma_7'],
                mode='lines',
                name='Moyenne mobile (7j)',
                line=dict(color='green', width=2, dash='dash'),
                opacity=0.7,
                hovertemplate='<b>Date:</b> %{x}<br><b>Moyenne 7j:</b> %{y:.1f} kWh<extra></extra>'
            ))
        
        # Configuration du graphique harmonis√©e
        title_text = 'Analyse de la Consommation √ânerg√©tique'
        
        fig.update_layout(
            title={
                'text': title_text,
                'x': 0.5,
                'xanchor': 'center',
                'font': {'size': 18, 'color': '#2E86AB'}
            },
            xaxis_title='Date',
            yaxis_title='Consommation (kWh)',
            hovermode='x unified',
            template='plotly_white',
            height=600,
            showlegend=True,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            ),
            margin=dict(l=50, r=50, t=80, b=50)
        )
        
        print(f"üìä Graphique g√©n√©r√© avec succ√®s - Format: {data_format}")
        
        return json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)

    except Exception as e:
        print(f"‚ùå Erreur dans create_advanced_chart: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def generate_professional_pdf(analysis, filename, df=None):
    """G√©n√®re un rapport PDF professionnel complet"""
    buffer = io.BytesIO()
    
    # Cr√©er le document PDF
    doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=18)
    
    # Styles
    styles = getSampleStyleSheet()
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=24,
        spaceAfter=30,
        textColor=colors.HexColor('#2E86AB'),
        alignment=TA_CENTER
    )
    
    heading_style = ParagraphStyle(
        'CustomHeading',
        parent=styles['Heading2'],
        fontSize=16,
        spaceAfter=12,
        textColor=colors.HexColor('#2E86AB'),
        alignment=TA_LEFT
    )
    
    normal_style = ParagraphStyle(
        'CustomNormal',
        parent=styles['Normal'],
        fontSize=11,
        spaceAfter=6,
        alignment=TA_LEFT
    )
    
    # Contenu du PDF
    story = []
    
    # Titre
    story.append(Paragraph("StatEnergie", title_style))
    story.append(Paragraph("Rapport d'Analyse √ânerg√©tique Professionnel", styles['Heading3']))
    story.append(Spacer(1, 20))
    
    # Informations du rapport
    info_data = [
        ['Fichier analys√©:', filename],
        ['Date de g√©n√©ration:', datetime.now().strftime('%d/%m/%Y √† %H:%M')],
        ['P√©riode d\'analyse:', 'Donn√©es compl√®tes du fichier'],
        ['Type d\'analyse:', 'Analyse avanc√©e avec d√©tection d\'anomalies']
    ]
    
    info_table = Table(info_data, colWidths=[150, 300])
    info_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (0, -1), colors.HexColor('#E8F4FD')),
        ('TEXTCOLOR', (0, 0), (-1, -1), colors.black),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('FONTNAME', (0, 0), (-1, -1), 'Helvetica'),
        ('FONTSIZE', (0, 0), (-1, -1), 10),
        ('BOTTOMPADDING', (0, 0), (-1, -1), 12),
        ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#2E86AB'))
    ]))
    
    story.append(info_table)
    story.append(Spacer(1, 20))
    
    # Gestion de la compatibilit√© avec l'ancienne et nouvelle structure
    efficiency_score = 0
    if 'statistics' in analysis and 'efficiency_score' in analysis['statistics']:
        efficiency_score = analysis['statistics']['efficiency_score']
    elif 'advanced_stats' in analysis and 'efficiency_metrics' in analysis['advanced_stats']:
        efficiency_score = analysis['advanced_stats']['efficiency_metrics']['overall_score']
    else:
        efficiency_score = 50  # Valeur par d√©faut
    
    # R√©sum√© ex√©cutif
    story.append(Paragraph("R√©sum√© Ex√©cutif", heading_style))
    
    if efficiency_score >= 75:
        summary = f"Votre installation pr√©sente une efficacit√© √©nerg√©tique <b>excellente</b> ({efficiency_score:.1f}/100)."
    elif efficiency_score >= 50:
        summary = f"Votre installation pr√©sente une efficacit√© √©nerg√©tique <b>mod√©r√©e</b> ({efficiency_score:.1f}/100)."
    else:
        summary = f"Votre installation pr√©sente une efficacit√© √©nerg√©tique <b>faible</b> ({efficiency_score:.1f}/100)."
    
    num_peaks = len(analysis.get('peaks', []))
    avg_consumption = analysis.get('avg_consumption', analysis.get('basic_stats', {}).get('avg_consumption', 0))
    
    summary += f" L'analyse r√©v√®le {num_peaks} pics de consommation et "
    summary += f"une consommation moyenne de {avg_consumption:.1f} kWh."
    
    story.append(Paragraph(summary, normal_style))
    story.append(Spacer(1, 15))
    
    # Statistiques d√©taill√©es
    story.append(Paragraph("Statistiques D√©taill√©es", heading_style))
    
    # Utiliser la nouvelle structure si disponible
    if 'basic_stats' in analysis:
        stats = analysis['basic_stats']
        adv_stats = analysis.get('advanced_stats', {})
        total_consumption = stats.get('total_consumption', 0)
        avg_consumption = stats.get('avg_consumption', 0)
        max_consumption = stats.get('max_consumption', 0)
        min_consumption = stats.get('min_consumption', 0)
        std_consumption = stats.get('std_consumption', 0)
        median = stats.get('median_consumption', 0)
        coefficient_variation = adv_stats.get('distribution', {}).get('coefficient_variation', 0)
    else:
        # Compatibilit√© avec l'ancienne structure
        total_consumption = analysis.get('total_consumption', 0)
        avg_consumption = analysis.get('avg_consumption', 0)
        max_consumption = analysis.get('max_consumption', 0)
        min_consumption = analysis.get('min_consumption', 0)
        std_consumption = analysis.get('std_consumption', 0)
        median = analysis.get('statistics', {}).get('median', 0)
        coefficient_variation = analysis.get('statistics', {}).get('coefficient_variation', 0)
    
    stats_data = [
        ['M√©trique', 'Valeur', 'Unit√©'],
        ['Consommation totale', f"{total_consumption:.1f}", 'kWh'],
        ['Consommation moyenne', f"{avg_consumption:.1f}", 'kWh'],
        ['Consommation maximale', f"{max_consumption:.1f}", 'kWh'],
        ['Consommation minimale', f"{min_consumption:.1f}", 'kWh'],
        ['√âcart-type', f"{std_consumption:.1f}", 'kWh'],
        ['M√©diane', f"{median:.1f}", 'kWh'],
        ['Coefficient de variation', f"{coefficient_variation:.2f}", '-'],
        ['Score d\'efficacit√©', f"{efficiency_score:.1f}", '/100']
    ]
    
    stats_table = Table(stats_data, colWidths=[200, 100, 50])
    stats_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2E86AB')),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
        ('FONTSIZE', (0, 0), (-1, -1), 10),
        ('BOTTOMPADDING', (0, 0), (-1, -1), 12),
        ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#2E86AB')),
        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#F5F5F5')])
    ]))
    
    story.append(stats_table)
    story.append(Spacer(1, 20))
    
    # Analyse des pics
    story.append(Paragraph("Analyse des Pics de Consommation", heading_style))
    
    peaks = analysis.get('peaks', [])
    if peaks:
        story.append(Paragraph(f"<b>{len(peaks)} pics de consommation</b> ont √©t√© d√©tect√©s:", normal_style))
        
        peaks_data = [['Date', 'Consommation (kWh)', 'D√©passement (%)', 'S√©v√©rit√©']]
        for peak in peaks[:10]:  # Limiter √† 10 pics
            date_str = peak.get('date', 'N/A')
            if date_str != 'N/A':
                try:
                    # Formatage de la date
                    date_obj = pd.to_datetime(date_str)
                    date_str = date_obj.strftime('%d/%m/%Y')
                except:
                    pass
            
            peaks_data.append([
                date_str,
                f"{peak.get('value', 0):.1f}",
                f"{peak.get('percentage_above_avg', 0):.1f}%",
                get_severity_display(peak.get('severity', 'medium'))
            ])
        
        peaks_table = Table(peaks_data, colWidths=[120, 100, 100, 80])
        peaks_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#FF6B6B')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
            ('FONTSIZE', (0, 0), (-1, -1), 9),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 10),
            ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#FF6B6B')),
            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#FFF5F5')])
        ]))
        
        story.append(peaks_table)
    else:
        story.append(Paragraph("‚úÖ Aucun pic de consommation significatif d√©tect√©.", normal_style))
    
    story.append(Spacer(1, 20))
    
    # Recommandations
    story.append(Paragraph("Recommandations Personnalis√©es", heading_style))
    
    recommendations = analysis.get('recommendations', [])
    if recommendations:
        for i, rec in enumerate(recommendations[:5], 1):  # Limiter √† 5 recommandations
            priority_color = {
                'high': colors.HexColor('#FF6B6B'),
                '√©lev√©e': colors.HexColor('#FF6B6B'),
                'medium': colors.HexColor('#FFA500'),
                'moyenne': colors.HexColor('#FFA500'),
                'low': colors.HexColor('#4CAF50'),
                'faible': colors.HexColor('#4CAF50')
            }.get(rec.get('priority', 'medium').lower(), colors.black)
            
            story.append(Paragraph(f"<b>{i}. {rec.get('title', 'Recommandation')}</b>", 
                                 ParagraphStyle('RecTitle', parent=normal_style, textColor=priority_color)))
            story.append(Paragraph(f"<b>Diagnostic:</b> {rec.get('message', 'Non sp√©cifi√©')}", normal_style))
            story.append(Paragraph(f"<b>Action recommand√©e:</b> {rec.get('action', 'Non sp√©cifi√©e')}", normal_style))
            story.append(Paragraph(f"<b>Potentiel d'√©conomie:</b> {rec.get('savings_potential', 'Non estim√©')}", normal_style))
            story.append(Spacer(1, 10))
    else:
        story.append(Paragraph("‚úÖ Votre profil de consommation est optimal.", normal_style))
    
    # === NOUVELLE SECTION : ANALYSE √âCONOMIQUE APPROFONDIE ===
    story.append(Spacer(1, 20))
    story.append(Paragraph("Analyse √âconomique et Opportunit√©s d'Investissement", heading_style))
    
    # R√©cup√©rer l'analyse des co√ªts
    cost_analysis = analysis.get('cost_analysis', {})
    
    if cost_analysis:
        # R√©sum√© financier
        annual_projection = cost_analysis.get('annual_projection', 0)
        total_savings = cost_analysis.get('potential_savings', {}).get('total_annuel', 0)
        
        story.append(Paragraph(f"<b>Projection annuelle :</b> {annual_projection:.0f}‚Ç¨", normal_style))
        story.append(Paragraph(f"<b>√âconomies potentielles :</b> {total_savings:.0f}‚Ç¨/an ({total_savings/annual_projection*100:.1f}%)", normal_style))
        story.append(Spacer(1, 10))
        
        # R√©partition des co√ªts
        cost_breakdown = cost_analysis.get('cost_breakdown', {})
        if cost_breakdown:
            story.append(Paragraph("R√©partition des Co√ªts", 
                                 ParagraphStyle('SubHeading', parent=normal_style, fontSize=12, textColor=colors.HexColor('#2E86AB'))))
            
            breakdown_data = [
                ['Poste de Co√ªt', 'Montant (‚Ç¨)', 'Pourcentage'],
                ['Consommation de base', f"{cost_breakdown.get('consommation_base', 0):.0f}", 
                 f"{100-cost_breakdown.get('pourcentage_pics', 0):.1f}%"],
                ['Pics de consommation', f"{cost_breakdown.get('pics_consommation', 0):.0f}", 
                 f"{cost_breakdown.get('pourcentage_pics', 0):.1f}%"]
            ]
            
            breakdown_table = Table(breakdown_data, colWidths=[180, 80, 80])
            breakdown_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#FFA500')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 9),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 10),
                ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#FFA500')),
                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#FFF8DC')])
            ]))
            
            story.append(breakdown_table)
            story.append(Spacer(1, 15))
        
        # Opportunit√©s d'investissement
        investments = cost_analysis.get('investment_opportunities', [])
        if investments:
            story.append(Paragraph("Top 3 des Investissements Recommand√©s", 
                                 ParagraphStyle('SubHeading', parent=normal_style, fontSize=12, textColor=colors.HexColor('#2E86AB'))))
            
            invest_data = [['Solution', 'Investissement (‚Ç¨)', '√âconomies/an (‚Ç¨)', 'ROI (ann√©es)']]
            for inv in investments[:3]:
                invest_data.append([
                    inv.get('solution', 'N/A'),
                    f"{inv.get('investissement', 0):,.0f}".replace(',', ' '),
                    f"{inv.get('economies_annuelles', 0):.0f}",
                    f"{inv.get('roi_annees', 0):.1f}"
                ])
            
            invest_table = Table(invest_data, colWidths=[140, 80, 80, 60])
            invest_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#4CAF50')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 8),
                ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#4CAF50')),
                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#F0F8F0')])
            ]))
            
            story.append(invest_table)
            story.append(Spacer(1, 15))
        
        # Recommandations √©conomiques prioritaires
        economic_recs = cost_analysis.get('economic_recommendations', [])
        if economic_recs:
            story.append(Paragraph("Plan d'Action √âconomique Prioritaire", 
                                 ParagraphStyle('SubHeading', parent=normal_style, fontSize=12, textColor=colors.HexColor('#2E86AB'))))
            
            for i, rec in enumerate(economic_recs[:3], 1):
                # Couleur selon la cat√©gorie
                if 'Urgente' in rec.get('categorie', ''):
                    cat_color = colors.HexColor('#FF6B6B')
                elif 'Court terme' in rec.get('categorie', ''):
                    cat_color = colors.HexColor('#FFA500')
                else:
                    cat_color = colors.HexColor('#4CAF50')
                
                story.append(Paragraph(f"<b>{i}. {rec.get('titre', 'Action recommand√©e')}</b>", 
                                     ParagraphStyle('EconRecTitle', parent=normal_style, textColor=cat_color, fontSize=11)))
                story.append(Paragraph(f"<b>Cat√©gorie:</b> {rec.get('categorie', 'N/A')}", normal_style))
                story.append(Paragraph(f"<b>Impact financier:</b> {rec.get('impact_financier', 0):.0f}‚Ç¨/an", normal_style))
                story.append(Paragraph(f"<b>ROI estim√©:</b> {rec.get('roi_estime', 'N/A')}", normal_style))
                story.append(Paragraph(f"<b>Investissement:</b> {rec.get('investissement_requis', 'N/A')}", normal_style))
                
                # Actions principales
                actions = rec.get('actions', [])
                if actions:
                    actions_text = "<br/>".join([f"‚Ä¢ {action}" for action in actions[:3]])
                    story.append(Paragraph(f"<b>Actions cl√©s:</b><br/>{actions_text}", normal_style))
                
                story.append(Spacer(1, 8))
    
    # Conclusion enrichie
    story.append(Spacer(1, 20))
    story.append(Paragraph("Conclusion et Prochaines √âtapes", heading_style))
    
    # Calcul du potentiel total d'√©conomies
    total_potential = cost_analysis.get('potential_savings', {}).get('total_annuel', 0) if cost_analysis else 0
    
    conclusion_text = f"""
    Cette analyse √©conomique r√©v√®le un potentiel d'optimisation significatif de {total_potential:.0f}‚Ç¨ par an.
    Votre score d'efficacit√© de {efficiency_score:.1f}/100 indique des opportunit√©s d'am√©lioration concr√®tes.
    
    <b>Prochaines √©tapes recommand√©es :</b>
    1. Mettre en place les actions imm√©diates (0-3 mois)
    2. √âvaluer les investissements √† court terme (3-12 mois) 
    3. Planifier les optimisations structurelles (1-3 ans)
    4. Suivre mensuellement les performances √©nerg√©tiques
    
    <b>Support StatEnergie :</b>
    Nos experts peuvent vous accompagner dans la mise en ≈ìuvre de ces recommandations
    et le suivi de vos √©conomies d'√©nergie. Contactez-nous pour un audit personnalis√©.
    """
    
    story.append(Paragraph(conclusion_text, normal_style))
    
    # G√©n√©rer le PDF
    doc.build(story)
    
    # R√©initialiser le buffer
    buffer.seek(0)
    return buffer

# === FONCTIONS D'ANALYSE SP√âCIFIQUES ENTREPRISE ===

def analyze_hp_hc_consumption(df):
    """Analyse la consommation HP/HC"""
    analysis = {
        'total_hp': 0,
        'total_hc': 0,
        'ratio_hp_hc': 0,
        'avg_hp': 0,
        'avg_hc': 0,
        'peak_hp': 0,
        'peak_hc': 0,
        'efficiency_score': 0,
        'recommendations': []
    }
    
    if 'hp_consumption' not in df.columns or 'hc_consumption' not in df.columns:
        return analysis
    
    # Calculs de base
    total_hp = df['hp_consumption'].sum()
    total_hc = df['hc_consumption'].sum()
    
    analysis.update({
        'total_hp': float(total_hp),
        'total_hc': float(total_hc),
        'ratio_hp_hc': float(total_hp / total_hc) if total_hc > 0 else 0,
        'avg_hp': float(df['hp_consumption'].mean()),
        'avg_hc': float(df['hc_consumption'].mean()),
        'peak_hp': float(df['hp_consumption'].max()),
        'peak_hc': float(df['hc_consumption'].max())
    })
    
    # Score d'efficacit√© bas√© sur la r√©partition HP/HC
    # Id√©alement, HC devrait √™tre plus √©lev√© (tarif plus avantageux)
    if total_hc > total_hp:
        analysis['efficiency_score'] = 85  # Bon usage
    elif total_hc > total_hp * 0.8:
        analysis['efficiency_score'] = 70  # Acceptable
    else:
        analysis['efficiency_score'] = 45  # √Ä am√©liorer
    
    # Recommandations
    if analysis['ratio_hp_hc'] > 1.5:
        analysis['recommendations'].append("Optimiser l'utilisation en heures creuses pour r√©duire les co√ªts")
    if analysis['ratio_hp_hc'] < 0.5:
        analysis['recommendations'].append("Excellente utilisation des heures creuses - maintenir cette r√©partition")
    
    return analysis

def analyze_zone_consumption(df):
    """Analyse la consommation par zone"""
    analysis = {
        'zones_summary': {},
        'total_zones': 0,
        'most_consuming_zone': '',
        'least_consuming_zone': '',
        'zone_efficiency': {},
        'recommendations': []
    }
    
    if 'zone' not in df.columns:
        return analysis
    
    # Analyse par zone
    zone_stats = df.groupby('zone').agg({
        'consumption': ['sum', 'mean', 'count'],
        'estimated_bill': 'sum' if 'estimated_bill' in df.columns else 'size'
    }).round(2)
    
    zone_stats.columns = ['total_consumption', 'avg_consumption', 'count_readings', 'total_cost']
    
    # Convertir en dictionnaire
    analysis['zones_summary'] = zone_stats.to_dict('index')
    analysis['total_zones'] = len(zone_stats)
    
    # Zone la plus/moins consommatrice
    if not zone_stats.empty:
        analysis['most_consuming_zone'] = zone_stats['total_consumption'].idxmax()
        analysis['least_consuming_zone'] = zone_stats['total_consumption'].idxmin()
    
    # Efficacit√© par zone (consommation par lecture)
    for zone in zone_stats.index:
        efficiency = zone_stats.loc[zone, 'avg_consumption']
        if efficiency > 2000:
            analysis['zone_efficiency'][zone] = '√âlev√©e'
        elif efficiency > 1000:
            analysis['zone_efficiency'][zone] = 'Mod√©r√©e'
        else:
            analysis['zone_efficiency'][zone] = 'Optimale'
    
    # Recommandations
    if analysis['total_zones'] > 1:
        max_zone = analysis['most_consuming_zone']
        analysis['recommendations'].append(f"Focus sur l'optimisation de la zone {max_zone}")
    
    return analysis

def analyze_billing_patterns(df):
    """Analyse les patterns de facturation"""
    analysis = {
        'total_cost': 0,
        'avg_daily_cost': 0,
        'cost_trend': 'stable',
        'cost_variability': 'faible',
        'projected_monthly': 0,
        'projected_yearly': 0,
        'cost_efficiency': 'good',
        'recommendations': []
    }
    
    if 'estimated_bill' not in df.columns:
        return analysis
    
    # Calculs de base
    total_cost = df['estimated_bill'].sum()
    avg_cost = df['estimated_bill'].mean()
    
    analysis.update({
        'total_cost': float(total_cost),
        'avg_daily_cost': float(avg_cost)
    })
    
    # Projections
    if 'date' in df.columns:
        df['date'] = pd.to_datetime(df['date'])
        days_covered = (df['date'].max() - df['date'].min()).days + 1
        if days_covered > 0:
            daily_avg = total_cost / days_covered
            analysis['projected_monthly'] = float(daily_avg * 30)
            analysis['projected_yearly'] = float(daily_avg * 365)
    
    # Variabilit√© des co√ªts
    cost_std = df['estimated_bill'].std()
    if cost_std / avg_cost > 0.3:
        analysis['cost_variability'] = '√©lev√©e'
    elif cost_std / avg_cost > 0.15:
        analysis['cost_variability'] = 'mod√©r√©e'
    else:
        analysis['cost_variability'] = 'faible'
    
    # Efficacit√© des co√ªts (‚Ç¨/kWh)
    if 'consumption' in df.columns:
        cost_per_kwh = avg_cost / df['consumption'].mean()
        if cost_per_kwh < 0.15:
            analysis['cost_efficiency'] = 'excellent'
        elif cost_per_kwh < 0.20:
            analysis['cost_efficiency'] = 'good'
        else:
            analysis['cost_efficiency'] = 'to_improve'
    
    # Recommandations
    if analysis['cost_variability'] == '√©lev√©e':
        analysis['recommendations'].append("Analyser les pics de consommation pour stabiliser les co√ªts")
    if analysis['projected_yearly'] > 50000:
        analysis['recommendations'].append("Consid√©rer un audit √©nerg√©tique approfondi")
    
    return analysis

def calculate_data_quality_score(df):
    """Calcule un score de qualit√© des donn√©es bas√© sur plusieurs crit√®res"""
    score = 100  # Score de d√©part parfait
    
    # Si le DataFrame est vide ou None
    if df is None or df.empty:
        return 0
    
    # V√©rifier les colonnes essentielles
    essential_columns = ['consumption', 'date']
    for col in essential_columns:
        if col not in df.columns:
            score -= 30  # P√©nalit√© importante pour l'absence de colonnes essentielles
    
    # Si consommation existe, v√©rifier la qualit√©
    if 'consumption' in df.columns:
        # Pourcentage de valeurs manquantes
        missing_pct = df['consumption'].isna().mean() * 100
        score -= min(30, missing_pct * 3)  # Jusqu'√† -30 points pour les valeurs manquantes
        
        # Pourcentage de valeurs nulles
        zero_pct = (df['consumption'] == 0).mean() * 100
        score -= min(15, zero_pct * 1.5)  # Jusqu'√† -15 points pour trop de z√©ros
        
        # Valeurs n√©gatives (g√©n√©ralement des erreurs)
        negative_pct = (df['consumption'] < 0).mean() * 100
        score -= min(20, negative_pct * 10)  # Jusqu'√† -20 points pour les valeurs n√©gatives
        
        # V√©rifier les valeurs aberrantes (outliers)
        if len(df) > 5:
            q1 = df['consumption'].quantile(0.25)
            q3 = df['consumption'].quantile(0.75)
            iqr = q3 - q1
            outlier_pct = ((df['consumption'] < (q1 - 3 * iqr)) | (df['consumption'] > (q3 + 3 * iqr))).mean() * 100
            score -= min(15, outlier_pct * 3)  # Jusqu'√† -15 points pour les valeurs aberrantes
    
    # V√©rifier la r√©gularit√© des dates si elles existent
    if 'date' in df.columns and not df['date'].isna().all():
        try:
            df_with_date = df.copy()
            df_with_date['date'] = pd.to_datetime(df_with_date['date'])
            df_with_date = df_with_date.sort_values('date')
            
            # V√©rifier la p√©riode couverte (pr√©f√©rer au moins 30 jours pour une analyse pertinente)
            date_range = (df_with_date['date'].max() - df_with_date['date'].min()).days
            if date_range < 30:
                score -= min(10, (30 - date_range) / 3)  # Jusqu'√† -10 points pour une p√©riode trop courte
            
            # V√©rifier les √©carts entre les dates
            if len(df_with_date) > 1:
                df_with_date['date_diff'] = df_with_date['date'].diff().dt.days
                irregular_pct = (df_with_date['date_diff'].dropna() != df_with_date['date_diff'].dropna().mode()[0]).mean() * 100
                score -= min(10, irregular_pct / 10)  # Jusqu'√† -10 points pour des donn√©es irr√©guli√®res
        except:
            score -= 10  # Erreur dans le traitement des dates
    
    # Bonus pour la richesse des donn√©es
    extra_useful_columns = ['hp_consumption', 'hc_consumption', 'estimated_bill', 'zone', 'temperature']
    for col in extra_useful_columns:
        if col in df.columns and not df[col].isna().all():
            score += 3  # +3 points par colonne utile suppl√©mentaire
    
    # Normalisation finale du score entre 0 et 100
    return max(0, min(100, score))

def create_dataframe_from_manual_entry(bill_data):
    """Cr√©e un DataFrame optimis√© √† partir des donn√©es de facturation saisies manuellement"""
    try:
        print(f"‚öôÔ∏è Cr√©ation d'un DataFrame √† partir des donn√©es manuelles: {bill_data}")
        
        # S'assurer que les valeurs num√©riques sont correctement converties
        consumption = 0
        try:
            consumption = float(bill_data.get("consumption_kwh", 0))
        except:
            consumption = 100  # Valeur par d√©faut si la conversion √©choue
            
        amount = 0
        try:
            amount = float(bill_data.get("amount", 0))
        except:
            amount = 50  # Valeur par d√©faut si la conversion √©choue
        
        # Gestion am√©lior√©e des dates
        bill_date = datetime.now()
        try:
            if bill_data.get("bill_date"):
                bill_date = pd.to_datetime(bill_data.get("bill_date"))
            else:
                bill_date = datetime.now()
        except:
            bill_date = datetime.now()
            
        # P√©riode de facturation
        period_start = bill_date - timedelta(days=30)  # Par d√©faut: 30 jours avant
        period_end = bill_date  # Par d√©faut: date de facture
        
        try:
            if bill_data.get("period_start"):
                period_start = pd.to_datetime(bill_data.get("period_start"))
        except:
            pass
            
        try:
            if bill_data.get("period_end"):
                period_end = pd.to_datetime(bill_data.get("period_end"))
        except:
            pass
        
        # Donn√©es de base pour le DataFrame
        data = {
            "provider": [bill_data.get("provider", "Non sp√©cifi√©")],
            "date": [bill_date],
            "consumption": [consumption],
            "estimated_bill": [amount],
            "consumption_kwh": [consumption],  # Pour la compatibilit√©
            "period_start": [period_start],
            "period_end": [period_end],
            "client_ref": [bill_data.get("client_ref", "")],
            "meter_number": [bill_data.get("meter_number", "")]
        }
            
        # Cr√©er le DataFrame de base
        df_base = pd.DataFrame(data)
        
        # G√©n√©rer une s√©rie temporelle bas√©e sur les donn√©es saisies
        # Cette √©tape est cruciale pour permettre une analyse significative
        days_in_period = (period_end - period_start).days
        if days_in_period <= 0:
            days_in_period = 30  # P√©riode minimale par d√©faut
        
        # Calculer la consommation journali√®re moyenne
        daily_consumption = consumption / days_in_period
        daily_cost = amount / days_in_period
        
        # G√©n√©rer des points r√©partis sur la p√©riode
        num_points = min(30, days_in_period)  # Maximum 30 points
        date_range = pd.date_range(start=period_start, end=period_end, periods=num_points)
        
        # Cr√©er des variations r√©alistes
        variation_factor = 0.3  # 30% de variation
        consumption_values = [daily_consumption * (1 + variation_factor * (np.random.random() - 0.5)) for _ in range(num_points)]
        bill_values = [daily_cost * (1 + variation_factor * (np.random.random() - 0.5)) for _ in range(num_points)]
        
        # Construire le DataFrame final
        df = pd.DataFrame({
            "date": date_range,
            "consumption": consumption_values,
            "estimated_bill": bill_values,
            "provider": [bill_data.get("provider", "Non sp√©cifi√©")] * num_points,
            "client_ref": [bill_data.get("client_ref", "")] * num_points,
            "meter_number": [bill_data.get("meter_number", "")] * num_points,
            "consumption_kwh": consumption_values,  # Pour la compatibilit√©
            "source_type": ["manuel"] * num_points  # Marquer les donn√©es comme manuelles
        })
        
        print(f"‚úÖ DataFrame cr√©√© avec succ√®s: {df.shape} lignes et {len(df.columns)} colonnes")
        print(f"üìä Aper√ßu des donn√©es g√©n√©r√©es:\n{df.head(3)}")
        
        return df
    
    except Exception as e:
        print(f"‚ùå Erreur lors de la cr√©ation du DataFrame manuel: {str(e)}")
        traceback.print_exc()
        
        # Retourner un DataFrame minimal mais fonctionnel pour √©viter les erreurs
        default_dates = [datetime.now() - timedelta(days=i*5) for i in range(10)]
        default_consumption = [100 - i*5 for i in range(10)]
        default_bill = [50 - i*2.5 for i in range(10)]
        
        return pd.DataFrame({
            "date": default_dates,
            "consumption": default_consumption,
            "estimated_bill": default_bill,
            "provider": ["Saisie manuelle"] * 10,
            "consumption_kwh": default_consumption,  # Pour la compatibilit√©
            "source_type": ["manuel"] * 10
        })

# Routes Flask
@app.route('/')
def index():
    """Page d'accueil"""
    return render_template('index.html')

@app.route('/formats')
def formats():
    """Page des formats de fichiers support√©s"""
    return render_template('formats.html')

@app.route('/upload', methods=['GET', 'POST'])
def upload():
    """Gestion de l'upload de fichiers"""
    if request.method == 'POST':
        # V√©rifier si un fichier a √©t√© s√©lectionn√©
        if 'file' not in request.files:
            flash('Aucun fichier s√©lectionn√©.')
            return redirect(request.url)
        
        file = request.files['file']
        
        if file.filename == '':
            flash('Aucun fichier s√©lectionn√©.')
            return redirect(request.url)
        
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{timestamp}_{filename}"
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(filepath)
            
            # Si c'est un fichier PDF, traiter d'abord avec l'analyseur PDF
            if filename.lower().endswith('.pdf'):
                try:
                    # Traiter le fichier PDF pour en extraire les donn√©es
                    pdf_analyzer = PDFBillAnalyzer()
                    bill_data = pdf_analyzer.process_pdf_bill(filepath)
                    
                    if "error" in bill_data:
                        flash(f"Impossible d'analyser le PDF: {bill_data['error']}")
                        return redirect(request.url)
                    
                    # Cr√©er un DataFrame √† partir des donn√©es de facturation
                    df = pdf_analyzer.create_dataframe_from_bill(bill_data)
                    
                    if df is None or df.empty:
                        flash("Impossible d'extraire des donn√©es valides du PDF.")
                        return redirect(request.url)
                    
                    # Sauvegarder les donn√©es extraites dans un CSV temporaire
                    csv_filename = filename.replace('.pdf', '.csv')
                    csv_filepath = os.path.join(app.config['UPLOAD_FOLDER'], csv_filename)
                    df.to_csv(csv_filepath, index=False)
                    
                    flash('PDF analys√© et donn√©es extraites avec succ√®s!')
                    return redirect(url_for('dashboard', filename=csv_filename))
                except Exception as e:
                    flash(f"Erreur lors du traitement du PDF: {str(e)}")
                    return redirect(request.url)
            else:
                # Traitement normal pour les autres types de fichiers
                flash('Fichier upload√© avec succ√®s!')
                return redirect(url_for('dashboard', filename=filename))
        else:
            flash('Type de fichier non autoris√©. Utilisez CSV, Excel, JSON ou PDF.')
            return redirect(request.url)
    
    return render_template('upload.html')

@app.route('/dashboard/<filename>')
def dashboard(filename):
    """Dashboard principal - redirige vers l'analyse avanc√©e"""
    return redirect(url_for('dashboard_advanced', filename=filename))

@app.route('/dashboard_advanced/<filename>')
def dashboard_advanced(filename):
    """Dashboard avanc√© avec analyse enrichie"""
    print(f"üîç DEBUG: Entr√©e dans dashboard_advanced avec filename: {filename}")
    
    try:
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        print(f"üîç DEBUG: Chemin fichier: {file_path}")
        
        # V√©rifier si c'est une analyse de donn√©es manuelles
        is_manual = "manual" in filename
        if is_manual:
            print(f"üìù MANUEL: Traitement des donn√©es saisies manuellement: {filename}")
        
        if not os.path.exists(file_path):
            print(f"‚ùå DEBUG: Fichier non trouv√©: {file_path}")
            flash('Fichier non trouv√©.')
            return redirect(url_for('index'))
        
        print(f"‚úÖ DEBUG: Fichier existe, d√©but de lecture...")
        
        # Lire le fichier selon son extension avec gestion d'encodage
        try:
            if filename.endswith('.csv'):
                # Essayer diff√©rents encodages
                for encoding in ['utf-8', 'latin1', 'cp1252', 'iso-8859-1']:
                    try:
                        df = pd.read_csv(file_path, encoding=encoding)
                        print(f"‚úÖ Fichier lu avec l'encodage: {encoding}")
                        break
                    except UnicodeDecodeError:
                        continue
                else:
                    # Si aucun encodage ne fonctionne
                    df = pd.read_csv(file_path, encoding='utf-8', errors='ignore')
                    print("‚ö†Ô∏è  Fichier lu avec gestion d'erreurs d'encodage")
            elif filename.endswith('.xlsx'):
                df = pd.read_excel(file_path)
            elif filename.endswith('.json'):
                df = pd.read_json(file_path)
            else:
                flash('Format de fichier non support√©.')
                return redirect(url_for('index'))
        except Exception as e:
            flash(f'Erreur lors de la lecture du fichier: {str(e)}')
            return redirect(url_for('index'))
        
        print(f"üìä Colonnes d√©tect√©es: {list(df.columns)}")
        print(f"üìè Dimensions: {df.shape}")
        print(f"üîç Aper√ßu des premi√®res lignes:")
        print(df.head())
        
        # Effectuer l'analyse avanc√©e (qui inclut la d√©tection de format et standardisation)
        try:
            print("üîÑ D√©marrage de l'analyse...")
            analysis = analyze_consumption_data(df)
            print("‚úÖ Analyse termin√©e avec succ√®s")
        except Exception as e:
            print(f"‚ùå Erreur pendant l'analyse: {str(e)}")
            print(f"üìã Type d'erreur: {type(e).__name__}")
            import traceback
            print("üìù Traceback complet:")
            traceback.print_exc()
            flash(f'Erreur lors de l\'analyse: {str(e)}')
            return redirect(url_for('index'))
        
        # G√©n√©rer le graphique
        try:
            print("üìà G√©n√©ration du graphique...")
            
            # Pr√©parer le DataFrame pour le graphique
            df_for_chart = df.copy()
            
            # Pour le format facturation, ajouter les colonnes n√©cessaires
            data_format = analysis.get('data_format', 'standard')
            
            if data_format == 'enterprise_facturation':
                # Ajouter une colonne date si elle n'existe pas
                if 'date' not in df_for_chart.columns:
                    if 'Mois' in df_for_chart.columns:
                        df_for_chart['date'] = pd.to_datetime(df_for_chart['Mois'] + '-01')
                    else:
                        # Date par d√©faut
                        df_for_chart['date'] = pd.date_range(start='2024-01-01', periods=len(df_for_chart), freq='M')
                
                # Ajouter une colonne consumption si elle n'existe pas
                if 'consumption' not in df_for_chart.columns:
                    if 'Consommation totale (kWh)' in df_for_chart.columns:
                        df_for_chart['consumption'] = df_for_chart['Consommation totale (kWh)']
                    elif 'Consommation (kWh)' in df_for_chart.columns:
                        df_for_chart['consumption'] = df_for_chart['Consommation (kWh)']
                    else:
                        # Utiliser la premi√®re colonne num√©rique
                        numeric_cols = df_for_chart.select_dtypes(include=[np.number]).columns
                        if len(numeric_cols) > 0:
                            df_for_chart['consumption'] = df_for_chart[numeric_cols[0]]
            
            chart_data = create_advanced_chart(df_for_chart, analysis)
            print("‚úÖ Graphique g√©n√©r√© avec succ√®s")
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration du graphique: {str(e)}")
            import traceback
            print("üìù Traceback g√©n√©ration graphique:")
            traceback.print_exc()
            chart_data = None
        
        # Date d'analyse
        analysis_date = datetime.now().strftime('%d/%m/%Y √† %H:%M')
        
        print(f"üéØ DEBUG: Avant render_template dashboard_advanced.html")
        print(f"üéØ DEBUG: analysis keys: {list(analysis.keys()) if analysis else 'None'}")
        print(f"üéØ DEBUG: chart_data exists: {chart_data is not None}")
        
        result = render_template('dashboard_advanced.html', 
                             analysis=analysis,
                             chart_data=chart_data,
                             filename=filename,
                             analysis_date=analysis_date)
        
        print(f"‚úÖ DEBUG: Template rendu avec succ√®s, retour de la r√©ponse")
        return result
        
    except Exception as e:
        print(f"‚ùå DEBUG: Exception dans dashboard_advanced: {str(e)}")
        import traceback
        traceback.print_exc()
        flash(f'Erreur lors de l\'analyse: {str(e)}')
        return redirect(url_for('index'))

@app.route('/generate_report/<filename>')
def generate_report(filename):
    """G√©n√©ration du rapport PDF professionnel"""
    try:
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        
        if not os.path.exists(filepath):
            flash('Fichier non trouv√©.')
            return redirect(url_for('upload_file'))
        
        # Charger et analyser les donn√©es
        if filename.endswith('.csv'):
            df = pd.read_csv(filepath)
        elif filename.endswith('.xlsx'):
            df = pd.read_excel(filepath)
        elif filename.endswith('.json'):
            df = pd.read_json(filepath)
        
        # Standardiser les colonnes
        if 'Date' in df.columns and 'date' not in df.columns:
            df['date'] = df['Date']
        if 'Consommation' in df.columns and 'consumption' not in df.columns:
            df['consumption'] = df['Consommation']
        if 'kWh' in df.columns and 'consumption' not in df.columns:
            df['consumption'] = df['kWh']
        
        analysis = analyze_consumption_data(df)
        
        # G√©n√©rer le PDF professionnel
        pdf_buffer = generate_professional_pdf(analysis, filename, df)
        
        return send_file(
            pdf_buffer,
            as_attachment=True,
            download_name=f'rapport_energetique_{filename.split(".")[0]}.pdf',
            mimetype='application/pdf'
        )
        
    except Exception as e:
        flash(f'Erreur lors de la g√©n√©ration du rapport: {str(e)}')
       
        return redirect(url_for('dashboard', filename=filename))

@app.route('/sample_data')
def sample_data():
    """G√©n√®re des donn√©es d'exemple pour test"""
    dates = pd.date_range(start='2024-01-01', end='2024-12-31', freq='D')
    np.random.seed(42)
    
    # Simuler une consommation r√©aliste
    base_consumption = 180
    seasonal_variation = 60 * np.sin(2 * np.pi * np.arange(len(dates)) / 365)
    weekly_pattern = 30 * np.sin(2 * np.pi * np.arange(len(dates)) / 7)
    random_noise = np.random.normal(0, 25, len(dates))
    
    consumption = base_consumption + seasonal_variation + weekly_pattern + random_noise
    consumption = np.maximum(consumption, 50)  # Minimum 50 kWh
    
    # Ajouter des pics r√©alistes
    peak_days = np.random.choice(len(dates), 20, replace=False)
    consumption[peak_days] *= np.random.uniform(1.8, 2.5, len(peak_days))
    
    sample_data = {
        'dates': dates.strftime('%Y-%m-%d').tolist(),
        'consumption': consumption.tolist()
    }
    
    return jsonify(sample_data)

# Stockage temporaire des r√©sultats d'analyse PDF
pdf_analysis_results = {}

@app.route('/pdf-analysis')
def pdf_analysis():
    """Page d'analyse des factures PDF"""
    return render_template('pdf_analysis.html')

@app.route('/analyze-sample-pdf')
def analyze_sample_pdf():
    """Analyse la facture exemple"""
    # Utiliser la facture exemple fournie
    file_path = 'facture_test.pdf'
    
    if not os.path.exists(file_path):
        flash('Facture exemple non trouv√©e')
        return redirect(url_for('pdf_analysis'))
    
    # Analyser le PDF
    analyzer = PDFBillAnalyzer()
    result = analyzer.process_pdf_bill(file_path)
    
    # G√©n√©rer un ID unique pour cette analyse
    pdf_id = str(uuid.uuid4())
    pdf_analysis_results[pdf_id] = {
        'result': result,
        'file_path': file_path
    }
    
    # R√©cup√©rer le texte de debug
    debug_text = analyzer.get_debug_text()
    
    return render_template('pdf_analysis.html', result=result, pdf_id=pdf_id, debug_text=debug_text)

@app.route('/export-pdf-data/<pdf_id>')
def export_pdf_data(pdf_id):
    """Exporte les donn√©es extraites de la facture au format CSV"""
    if pdf_id not in pdf_analysis_results:
        flash('Analyse non trouv√©e')
        return redirect(url_for('pdf_analysis'))
    
    result = pdf_analysis_results[pdf_id]['result']
    
    # Cr√©er un DataFrame √† partir des r√©sultats
    analyzer = PDFBillAnalyzer()
    df = analyzer.create_dataframe_from_bill(result)
    
    if df is None:
        flash("Impossible de cr√©er un fichier d'export - donn√©es insuffisantes")
        return redirect(url_for('pdf_analysis'))
    
    # Sauvegarder en CSV temporaire
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.csv')
    df.to_csv(temp_file.name, index=False, sep=';')
    
    # Envoyer le fichier CSV
    return send_file(
        temp_file.name,
        mimetype='text/csv',
        as_attachment=True,
        download_name='donnees_facture.csv'
    )

@app.route('/analyze-pdf', methods=['GET', 'POST'])
def analyze_pdf():
    """Analyse une facture PDF upload√©e avec options avanc√©es"""
    if request.method == 'POST':
        # V√©rifier si un fichier a √©t√© t√©l√©charg√©
        if 'pdf_file' not in request.files:
            flash('Aucun fichier s√©lectionn√©')
            return redirect(request.url)
        
        file = request.files['pdf_file']
        
        if file.filename == '':
            flash('Aucun fichier s√©lectionn√©')
            return redirect(request.url)
        
        if file and file.filename.lower().endswith('.pdf'):
            # R√©cup√©rer les options d'extraction
            extraction_mode = request.form.get('extraction_mode', 'standard')
            extract_tables = 'extract_tables' in request.form
            debug_mode = 'debug_mode' in request.form
            specific_provider = request.form.get('specific_provider', '')
            
            # Options d'analyse
            options = {
                "extraction_mode": extraction_mode,
                "extract_tables": extract_tables,
                "debug_mode": debug_mode
            }
            
            if specific_provider:
                options["specific_provider"] = specific_provider
            
            # Sauvegarder le fichier
            filename = secure_filename(file.filename)
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(file_path)
            
            # Analyser le PDF
            analyzer = PDFBillAnalyzer()
            result = analyzer.process_pdf_bill(file_path, options)
            
            # R√©cup√©rer le texte de debug si disponible
            debug_text = None
            if debug_mode:
                debug_text = analyzer.get_debug_text()
            
            # G√©n√©rer un ID unique pour cette analyse
            import uuid
            pdf_id = str(uuid.uuid4())
            pdf_analysis_results[pdf_id] = {
                'result': result,
                'file_path': file_path,
                'options': options
            }
            
            return render_template('pdf_analysis.html', result=result, pdf_id=pdf_id, debug_text=debug_text)
    
    return render_template('pdf_analysis.html')

@app.route('/analyze-pdf-advanced/<pdf_id>/<mode>')
def analyze_pdf_advanced(pdf_id, mode):
    """R√©analyse un PDF d√©j√† t√©l√©charg√© avec un mode diff√©rent"""
    if pdf_id not in pdf_analysis_results:
        flash('Analyse non trouv√©e')
        return redirect(url_for('pdf_analysis'))
    
    # R√©cup√©rer le chemin du fichier de l'analyse pr√©c√©dente
    file_path = pdf_analysis_results[pdf_id]['file_path']
    
    if not os.path.exists(file_path):
        flash('Fichier PDF non trouv√©')
        return redirect(url_for('pdf_analysis'))
    
    # D√©finir les nouvelles options d'extraction
    options = {
        "extraction_mode": mode,
        "extract_tables": True,
        "debug_mode": True
    }
    
    # R√©analyser le PDF avec les nouvelles options
    analyzer = PDFBillAnalyzer()
    result = analyzer.process_pdf_bill(file_path, options)
    
    # R√©cup√©rer le texte de debug
    debug_text = analyzer.get_debug_text()
    
    # G√©n√©rer un nouvel ID pour cette analyse
    import uuid
    new_pdf_id = str(uuid.uuid4())
    pdf_analysis_results[new_pdf_id] = {
        'result': result,
        'file_path': file_path,
        'options': options
    }
    
    return render_template('pdf_analysis.html', result=result, pdf_id=new_pdf_id, debug_text=debug_text)

@app.route('/pdf-extraction-help')
def pdf_extraction_help():
    """Page d'aide pour les probl√®mes d'extraction PDF"""
    return render_template('pdf_extraction_help.html')

@app.route('/analyze-with-data/<pdf_id>')
def analyze_with_data(pdf_id):
    """Redirige vers l'analyse de donn√©es de la facture PDF ou saisie manuelle"""
    try:
        print(f"üîç Traitement de l'analyse pour PDF ID: {pdf_id}")
        
        if pdf_id not in pdf_analysis_results:
            flash('Analyse non trouv√©e - veuillez r√©essayer')
            return redirect(url_for('pdf_analysis'))
        
        result = pdf_analysis_results[pdf_id]['result']
        is_manual = pdf_analysis_results[pdf_id].get('manual_entry', False)
        source_text = "saisies manuellement" if is_manual else "extraites du PDF"
        print(f"üìã Donn√©es {source_text} r√©cup√©r√©es: {result}")
        
        # Cr√©er un DataFrame √† partir des r√©sultats
        df = None
        if is_manual:
            # Pour les donn√©es saisies manuellement
            print("üñãÔ∏è Cr√©ation du DataFrame √† partir des donn√©es saisies manuellement")
            df = create_dataframe_from_manual_entry(result)
        else:
            # Pour les donn√©es extraites d'un PDF
            print("üìÑ Cr√©ation du DataFrame √† partir des donn√©es PDF")
            analyzer = PDFBillAnalyzer()
            df = analyzer.create_dataframe_from_bill(result)
        
        if df is None:
            print("‚ùå √âchec de cr√©ation du DataFrame - donn√©es insuffisantes")
            flash("Impossible de cr√©er des donn√©es pour analyse - informations insuffisantes")
            return redirect(url_for('pdf_analysis'))
        
        print(f"‚úì DataFrame initial cr√©√©: {df.shape}")
        
        # V√©rification et ajout des colonnes obligatoires
        essential_columns = ['consumption', 'date', 'estimated_bill']
        
        # Assurer la pr√©sence de la colonne 'consumption'
        if 'consumption' not in df.columns:
            if 'consumption_kwh' in df.columns:
                print("‚ûï Ajout de colonne: consumption √† partir de consumption_kwh")
                df['consumption'] = df['consumption_kwh']
            else:
                # Cr√©er une colonne de consommation par d√©faut
                print("‚ö†Ô∏è Cr√©ation d'une colonne de consommation par d√©faut")
                if is_manual and 'amount' in result:
                    # Estimer la consommation √† partir du montant (approximation)
                    df['consumption'] = float(result.get('amount', 100)) * 5  # ~5 kWh par ‚Ç¨
                else:
                    df['consumption'] = 100  # Valeur par d√©faut
        
        # Assurer la pr√©sence de la colonne 'date'
        if 'date' not in df.columns:
            if 'bill_date' in df.columns:
                print("‚ûï Ajout de colonne: date √† partir de bill_date")
                df['date'] = pd.to_datetime(df['bill_date'], errors='coerce')
            elif 'period_start' in df.columns:
                print("‚ûï Ajout de colonne: date √† partir de period_start")
                df['date'] = pd.to_datetime(df['period_start'], errors='coerce')
            else:
                # Cr√©er une colonne de date par d√©faut
                print("‚ö†Ô∏è Cr√©ation d'une colonne de date par d√©faut")
                df['date'] = datetime.now()
        
        # Assurer que la date est au format datetime
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        
        # Assurer la pr√©sence de la colonne 'estimated_bill'
        if 'estimated_bill' not in df.columns:
            if 'amount' in df.columns:
                print("‚ûï Ajout de colonne: estimated_bill √† partir de amount")
                df['estimated_bill'] = df['amount']
            else:
                # Cr√©er une colonne de co√ªt par d√©faut
                print("‚ö†Ô∏è Cr√©ation d'une colonne de co√ªt par d√©faut")
                if is_manual and 'consumption_kwh' in result:
                    # Estimer le co√ªt √† partir de la consommation (approximation)
                    df['estimated_bill'] = float(result.get('consumption_kwh', 100)) * 0.20  # ~0.20 ‚Ç¨ par kWh
                else:
                    df['estimated_bill'] = 50  # Valeur par d√©faut
        
        # Sauvegarder temporairement en CSV pour l'analyse
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        source_type = "manual" if is_manual else "pdf"
        csv_filename = f"facture_{source_type}_{timestamp}.csv"
        csv_filepath = os.path.join(app.config['UPLOAD_FOLDER'], csv_filename)
        
        print(f"üíæ Sauvegarde du DataFrame enrichi ({df.shape[0]} lignes, {df.shape[1]} colonnes)")
        print(f"üìä Aper√ßu avant sauvegarde:\n{df.head(3)}")
        
        # V√©rifier qu'il n'y a pas de valeurs NaN dans les colonnes essentielles
        for col in essential_columns:
            if col in df.columns and df[col].isna().any():
                print(f"‚ö†Ô∏è Remplacement des valeurs NaN dans la colonne {col}")
                if col == 'date':
                    df[col] = df[col].fillna(datetime.now())
                elif col == 'consumption':
                    df[col] = df[col].fillna(100)
                elif col == 'estimated_bill':
                    df[col] = df[col].fillna(50)
        
        df.to_csv(csv_filepath, index=False)
        
        # Message de confirmation et redirection
        flash(f'Donn√©es {source_text} pr√™tes pour analyse avanc√©e')
        print(f"‚úÖ Redirection vers le dashboard avec le fichier: {csv_filename}")
        
        return redirect(url_for('dashboard_advanced', filename=csv_filename))
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'analyse des donn√©es: {str(e)}")
        traceback.print_exc()
        flash(f'Erreur lors de l\'analyse des donn√©es: {str(e)}')
        return redirect(url_for('pdf_analysis'))

@app.route('/compare-pdf-data/<pdf_id>')
def compare_pdf_data(pdf_id):
    """Redirige vers la page de comparaison avec les donn√©es de la facture"""
    if pdf_id not in pdf_analysis_results:
        flash('Analyse non trouv√©e')
        return redirect(url_for('pdf_analysis'))
    
    # Dans une application compl√®te, cette fonction permettrait de comparer
    # les donn√©es de cette facture avec d'autres donn√©es historiques
    flash('Fonctionnalit√© de comparaison √† venir dans une prochaine mise √† jour')
    return redirect(url_for('pdf_analysis'))

@app.route('/manual_bill_entry', methods=['GET', 'POST'])
def manual_bill_entry():
    """Page pour saisir manuellement les donn√©es d'une facture"""
    if request.method == 'POST':
        # R√©cup√©rer les donn√©es du formulaire
        bill_data = {
            "provider": request.form.get('provider', 'Non sp√©cifi√©'),
            "bill_date": request.form.get('bill_date'),
            "consumption_kwh": float(request.form.get('consumption_kwh', 0)) if request.form.get('consumption_kwh') else 0,
            "amount": float(request.form.get('amount', 0)) if request.form.get('amount') else 0,
            "period_start": request.form.get('period_start'),
            "period_end": request.form.get('period_end'),
            "client_ref": request.form.get('client_ref', ''),
            "meter_number": request.form.get('meter_number', '')
        }
        
        # G√©n√©rer un ID unique pour cette analyse manuelle
        pdf_id = str(uuid.uuid4())
        pdf_analysis_results[pdf_id] = {
            'result': bill_data,
            'manual_entry': True,
            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        flash('Donn√©es de facture enregistr√©es avec succ√®s')
        # Rediriger directement vers l'analyse des donn√©es
        return redirect(url_for('analyze_with_data', pdf_id=pdf_id))
    
    # Afficher le formulaire
    return render_template('manual_bill_entry.html')

def analyze_consumption_patterns(df):
    """Analyser les patterns de consommation pour l'analyse avanc√©e des donn√©es manuelles"""
    # D√©terminer la colonne de consommation √† utiliser
    consumption_col = 'consumption' if 'consumption' in df.columns else 'total_consumption'
    consumption = df[consumption_col]
    
    # Initialiser les r√©sultats d'analyse
    analysis = {
        'total': float(consumption.sum()),
        'average': float(consumption.mean()),
        'median': float(consumption.median()),
        'std': float(consumption.std()),
        'max': float(consumption.max()),
        'min': float(consumption.min()),
        'quartiles': {
            'q25': float(consumption.quantile(0.25)),
            'q75': float(consumption.quantile(0.75))
        },
        'coefficient_variation': float(consumption.std() / consumption.mean()) if consumption.mean() > 0 else 0,
        'trend': 'stable',
        'volatility': 'low'
    }
    
    # Analyser la tendance si des dates sont disponibles
    if 'date' in df.columns:
        df_sorted = df.sort_values('date').copy()
        x = np.arange(len(df_sorted))
        y = df_sorted[consumption_col].values
        
        if len(x) > 1:
            try:
                # Calculer la tendance lin√©aire
                from scipy import stats
                slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
                
                # Interpr√©ter la pente
                if slope > 0.05 * analysis['average']:
                    analysis['trend'] = 'increasing'
                elif slope < -0.05 * analysis['average']:
                    analysis['trend'] = 'decreasing'
                else:
                    analysis['trend'] = 'stable'
                
                # Stocker les donn√©es de r√©gression
                analysis['regression'] = {
                    'slope': float(slope),
                    'intercept': float(intercept),
                    'r_squared': float(r_value**2),
                    'p_value': float(p_value)
                }
            except:
                pass
    
    # D√©terminer la volatilit√©
    if analysis['coefficient_variation'] < 0.1:
        analysis['volatility'] = 'very_low'
    elif analysis['coefficient_variation'] < 0.2:
        analysis['volatility'] = 'low'
    elif analysis['coefficient_variation'] < 0.4:
        analysis['volatility'] = 'medium'
    else:
        analysis['volatility'] = 'high'
    
    # D√©tecter les pics de consommation
    threshold = analysis['average'] + 1.5 * analysis['std']
    peaks = df[df[consumption_col] > threshold]
    
    analysis['peaks'] = {
        'count': len(peaks),
        'percentage': len(peaks) / len(df) * 100,
        'average_magnitude': float(peaks[consumption_col].mean()) if len(peaks) > 0 else 0,
        'max_peak': float(peaks[consumption_col].max()) if len(peaks) > 0 else 0
    }
    
    # Calculer le surco√ªt potentiel d√ª aux pics
    if 'estimated_bill' in df.columns:
        avg_cost_per_kwh = df['estimated_bill'].sum() / consumption.sum() if consumption.sum() > 0 else 0.20
        peak_excess = peaks[consumption_col].sum() - (analysis['average'] * len(peaks))
        analysis['peaks']['estimated_cost_impact'] = float(peak_excess * avg_cost_per_kwh * 1.5)  # Majoration de 50% pour l'impact des pics
    
    # Ajouter des recommandations basiques
    analysis['recommendations'] = []
    
    if analysis['volatility'] in ['high', 'medium']:
        analysis['recommendations'].append({
            'type': 'volatility',
            'message': 'R√©duisez la variabilit√© de votre consommation pour optimiser vos co√ªts',
            'priority': 'high' if analysis['volatility'] == 'high' else 'medium',
            'potential_impact': 'significant'
        })
    
    if analysis['peaks']['percentage'] > 10:
        analysis['recommendations'].append({
            'type': 'peaks',
            'message': 'Attention aux pics de consommation fr√©quents qui peuvent impacter votre facture',
            'priority': 'high',
            'potential_impact': 'high'
        })
    
    if analysis['trend'] == 'increasing':
        analysis['recommendations'].append({
            'type': 'trend',
            'message': 'Votre consommation est en augmentation, analysez les causes de cette hausse',
            'priority': 'medium',
            'potential_impact': 'growing'
        })
    
    return analysis
